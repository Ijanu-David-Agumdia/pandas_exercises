{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Wind Statistics\n",
    "\n",
    "Check out [Wind Statistics Exercises Video Tutorial](https://youtu.be/2x3WsWiNV18) to watch a data scientist go through the exercises"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Introduction:\n",
    "\n",
    "The data have been modified to contain some missing values, identified by NaN.  \n",
    "Using pandas should make this exercise\n",
    "easier, in particular for the bonus question.\n",
    "\n",
    "You should be able to perform all of these operations without using\n",
    "a for loop or other looping construct.\n",
    "\n",
    "\n",
    "1. The data in 'wind.data' has the following format:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nYr Mo Dy   RPT   VAL   ROS   KIL   SHA   BIR   DUB   CLA   MUL   CLO   BEL   MAL\\n61  1  1 15.04 14.96 13.17  9.29   NaN  9.87 13.67 10.25 10.83 12.58 18.50 15.04\\n61  1  2 14.71   NaN 10.83  6.50 12.62  7.67 11.50 10.04  9.79  9.67 17.54 13.83\\n61  1  3 18.50 16.88 12.33 10.13 11.17  6.17 11.25   NaN  8.50  7.67 12.75 12.71\\n'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "Yr Mo Dy   RPT   VAL   ROS   KIL   SHA   BIR   DUB   CLA   MUL   CLO   BEL   MAL\n",
    "61  1  1 15.04 14.96 13.17  9.29   NaN  9.87 13.67 10.25 10.83 12.58 18.50 15.04\n",
    "61  1  2 14.71   NaN 10.83  6.50 12.62  7.67 11.50 10.04  9.79  9.67 17.54 13.83\n",
    "61  1  3 18.50 16.88 12.33 10.13 11.17  6.17 11.25   NaN  8.50  7.67 12.75 12.71\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "   The first three columns are year, month and day.  The\n",
    "   remaining 12 columns are average windspeeds in knots at 12\n",
    "   locations in Ireland on that day.   \n",
    "\n",
    "   More information about the dataset go [here](wind.desc)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import the dataset from this [address](https://github.com/guipsamora/pandas_exercises/blob/master/06_Stats/Wind_Stats/wind.data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Assign it to a variable called data and replace the first 3 columns by a proper datetime index."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Yr_Mo_Dy</th>\n",
       "      <th>RPT</th>\n",
       "      <th>VAL</th>\n",
       "      <th>ROS</th>\n",
       "      <th>KIL</th>\n",
       "      <th>SHA</th>\n",
       "      <th>BIR</th>\n",
       "      <th>DUB</th>\n",
       "      <th>CLA</th>\n",
       "      <th>MUL</th>\n",
       "      <th>CLO</th>\n",
       "      <th>BEL</th>\n",
       "      <th>MAL</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2061-01-01</td>\n",
       "      <td>15.04</td>\n",
       "      <td>14.96</td>\n",
       "      <td>13.17</td>\n",
       "      <td>9.29</td>\n",
       "      <td>NaN</td>\n",
       "      <td>9.87</td>\n",
       "      <td>13.67</td>\n",
       "      <td>10.25</td>\n",
       "      <td>10.83</td>\n",
       "      <td>12.58</td>\n",
       "      <td>18.50</td>\n",
       "      <td>15.04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2061-01-02</td>\n",
       "      <td>14.71</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10.83</td>\n",
       "      <td>6.50</td>\n",
       "      <td>12.62</td>\n",
       "      <td>7.67</td>\n",
       "      <td>11.50</td>\n",
       "      <td>10.04</td>\n",
       "      <td>9.79</td>\n",
       "      <td>9.67</td>\n",
       "      <td>17.54</td>\n",
       "      <td>13.83</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2061-01-03</td>\n",
       "      <td>18.50</td>\n",
       "      <td>16.88</td>\n",
       "      <td>12.33</td>\n",
       "      <td>10.13</td>\n",
       "      <td>11.17</td>\n",
       "      <td>6.17</td>\n",
       "      <td>11.25</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8.50</td>\n",
       "      <td>7.67</td>\n",
       "      <td>12.75</td>\n",
       "      <td>12.71</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2061-01-04</td>\n",
       "      <td>10.58</td>\n",
       "      <td>6.63</td>\n",
       "      <td>11.75</td>\n",
       "      <td>4.58</td>\n",
       "      <td>4.54</td>\n",
       "      <td>2.88</td>\n",
       "      <td>8.63</td>\n",
       "      <td>1.79</td>\n",
       "      <td>5.83</td>\n",
       "      <td>5.88</td>\n",
       "      <td>5.46</td>\n",
       "      <td>10.88</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2061-01-05</td>\n",
       "      <td>13.33</td>\n",
       "      <td>13.25</td>\n",
       "      <td>11.42</td>\n",
       "      <td>6.17</td>\n",
       "      <td>10.71</td>\n",
       "      <td>8.21</td>\n",
       "      <td>11.92</td>\n",
       "      <td>6.54</td>\n",
       "      <td>10.92</td>\n",
       "      <td>10.34</td>\n",
       "      <td>12.92</td>\n",
       "      <td>11.83</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Yr_Mo_Dy    RPT    VAL    ROS    KIL    SHA   BIR    DUB    CLA    MUL  \\\n",
       "0 2061-01-01  15.04  14.96  13.17   9.29    NaN  9.87  13.67  10.25  10.83   \n",
       "1 2061-01-02  14.71    NaN  10.83   6.50  12.62  7.67  11.50  10.04   9.79   \n",
       "2 2061-01-03  18.50  16.88  12.33  10.13  11.17  6.17  11.25    NaN   8.50   \n",
       "3 2061-01-04  10.58   6.63  11.75   4.58   4.54  2.88   8.63   1.79   5.83   \n",
       "4 2061-01-05  13.33  13.25  11.42   6.17  10.71  8.21  11.92   6.54  10.92   \n",
       "\n",
       "     CLO    BEL    MAL  \n",
       "0  12.58  18.50  15.04  \n",
       "1   9.67  17.54  13.83  \n",
       "2   7.67  12.75  12.71  \n",
       "3   5.88   5.46  10.88  \n",
       "4  10.34  12.92  11.83  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# parse_dates gets 0, 1, 2 columns and parses them as the index\n",
    "import pandas as pd\n",
    "data_url = 'https://raw.githubusercontent.com/guipsamora/pandas_exercises/master/06_Stats/Wind_Stats/wind.data'\n",
    "data = pd.read_csv(data_url, sep = \"\\s+\", parse_dates = [[0,1,2]]) \n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Year 2061? Do we really have data from this year? Create a function to fix it and apply it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'datetime' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[1;32mIn [3]\u001b[0m, in \u001b[0;36m<cell line: 9>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      6\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m datetime\u001b[38;5;241m.\u001b[39mdate(year, x\u001b[38;5;241m.\u001b[39mmonth, x\u001b[38;5;241m.\u001b[39mday)\n\u001b[0;32m      8\u001b[0m \u001b[38;5;66;03m# apply the function fix_century on the column and replace the values to the right ones\u001b[39;00m\n\u001b[1;32m----> 9\u001b[0m data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mYr_Mo_Dy\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[43mdata\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mYr_Mo_Dy\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfix_century\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     11\u001b[0m \u001b[38;5;66;03m# data.info()\u001b[39;00m\n\u001b[0;32m     12\u001b[0m data\u001b[38;5;241m.\u001b[39mhead()\n",
      "File \u001b[1;32mC:\\Anaconda\\lib\\site-packages\\pandas\\core\\series.py:4433\u001b[0m, in \u001b[0;36mSeries.apply\u001b[1;34m(self, func, convert_dtype, args, **kwargs)\u001b[0m\n\u001b[0;32m   4323\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mapply\u001b[39m(\n\u001b[0;32m   4324\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m   4325\u001b[0m     func: AggFuncType,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   4328\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[0;32m   4329\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m DataFrame \u001b[38;5;241m|\u001b[39m Series:\n\u001b[0;32m   4330\u001b[0m     \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   4331\u001b[0m \u001b[38;5;124;03m    Invoke function on values of Series.\u001b[39;00m\n\u001b[0;32m   4332\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   4431\u001b[0m \u001b[38;5;124;03m    dtype: float64\u001b[39;00m\n\u001b[0;32m   4432\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m-> 4433\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mSeriesApply\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconvert_dtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mC:\\Anaconda\\lib\\site-packages\\pandas\\core\\apply.py:1088\u001b[0m, in \u001b[0;36mSeriesApply.apply\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1084\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mf, \u001b[38;5;28mstr\u001b[39m):\n\u001b[0;32m   1085\u001b[0m     \u001b[38;5;66;03m# if we are a string, try to dispatch\u001b[39;00m\n\u001b[0;32m   1086\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mapply_str()\n\u001b[1;32m-> 1088\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply_standard\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mC:\\Anaconda\\lib\\site-packages\\pandas\\core\\apply.py:1143\u001b[0m, in \u001b[0;36mSeriesApply.apply_standard\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1137\u001b[0m         values \u001b[38;5;241m=\u001b[39m obj\u001b[38;5;241m.\u001b[39mastype(\u001b[38;5;28mobject\u001b[39m)\u001b[38;5;241m.\u001b[39m_values\n\u001b[0;32m   1138\u001b[0m         \u001b[38;5;66;03m# error: Argument 2 to \"map_infer\" has incompatible type\u001b[39;00m\n\u001b[0;32m   1139\u001b[0m         \u001b[38;5;66;03m# \"Union[Callable[..., Any], str, List[Union[Callable[..., Any], str]],\u001b[39;00m\n\u001b[0;32m   1140\u001b[0m         \u001b[38;5;66;03m# Dict[Hashable, Union[Union[Callable[..., Any], str],\u001b[39;00m\n\u001b[0;32m   1141\u001b[0m         \u001b[38;5;66;03m# List[Union[Callable[..., Any], str]]]]]\"; expected\u001b[39;00m\n\u001b[0;32m   1142\u001b[0m         \u001b[38;5;66;03m# \"Callable[[Any], Any]\"\u001b[39;00m\n\u001b[1;32m-> 1143\u001b[0m         mapped \u001b[38;5;241m=\u001b[39m \u001b[43mlib\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmap_infer\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1144\u001b[0m \u001b[43m            \u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1145\u001b[0m \u001b[43m            \u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# type: ignore[arg-type]\u001b[39;49;00m\n\u001b[0;32m   1146\u001b[0m \u001b[43m            \u001b[49m\u001b[43mconvert\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconvert_dtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1147\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1149\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(mapped) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(mapped[\u001b[38;5;241m0\u001b[39m], ABCSeries):\n\u001b[0;32m   1150\u001b[0m     \u001b[38;5;66;03m# GH#43986 Need to do list(mapped) in order to get treated as nested\u001b[39;00m\n\u001b[0;32m   1151\u001b[0m     \u001b[38;5;66;03m#  See also GH#25959 regarding EA support\u001b[39;00m\n\u001b[0;32m   1152\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m obj\u001b[38;5;241m.\u001b[39m_constructor_expanddim(\u001b[38;5;28mlist\u001b[39m(mapped), index\u001b[38;5;241m=\u001b[39mobj\u001b[38;5;241m.\u001b[39mindex)\n",
      "File \u001b[1;32mC:\\Anaconda\\lib\\site-packages\\pandas\\_libs\\lib.pyx:2870\u001b[0m, in \u001b[0;36mpandas._libs.lib.map_infer\u001b[1;34m()\u001b[0m\n",
      "Input \u001b[1;32mIn [3]\u001b[0m, in \u001b[0;36mfix_century\u001b[1;34m(x)\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfix_century\u001b[39m(x):\n\u001b[0;32m      5\u001b[0m   year \u001b[38;5;241m=\u001b[39m x\u001b[38;5;241m.\u001b[39myear \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m100\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m x\u001b[38;5;241m.\u001b[39myear \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1989\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m x\u001b[38;5;241m.\u001b[39myear\n\u001b[1;32m----> 6\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mdatetime\u001b[49m\u001b[38;5;241m.\u001b[39mdate(year, x\u001b[38;5;241m.\u001b[39mmonth, x\u001b[38;5;241m.\u001b[39mday)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'datetime' is not defined"
     ]
    }
   ],
   "source": [
    "# The problem is that the dates are 2061 and so on...\n",
    "\n",
    "# function that uses datetime\n",
    "def fix_century(x):\n",
    "  year = x.year - 100 if x.year > 1989 else x.year\n",
    "  return datetime.date(year, x.month, x.day)\n",
    "\n",
    "# apply the function fix_century on the column and replace the values to the right ones\n",
    "data['Yr_Mo_Dy'] = data['Yr_Mo_Dy'].apply(fix_century)\n",
    "\n",
    "# data.info()\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set the right dates as the index. Pay attention at the data type, it should be datetime64[ns]."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# transform Yr_Mo_Dy it to date type datetime64\n",
    "data[\"Yr_Mo_Dy\"] = pd.to_datetime(data[\"Yr_Mo_Dy\"])\n",
    "\n",
    "# set 'Yr_Mo_Dy' as the index\n",
    "data = data.set_index('Yr_Mo_Dy')\n",
    "\n",
    "data.head()\n",
    "# data.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compute how many values are missing for each location over the entire record.  \n",
    "#### They should be ignored in all calculations below. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# \"Number of non-missing values for each location: \"\n",
    "data.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compute how many non-missing values there are in total."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#number of columns minus the number of missing values for each location\n",
    "data.shape[0] - data.isnull().sum()\n",
    "\n",
    "#or\n",
    "\n",
    "data.notnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculate the mean windspeeds of the windspeeds over all the locations and all the times.\n",
    "#### A single number for the entire dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.sum().sum() / data.notna().sum().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create a DataFrame called loc_stats and calculate the min, max and mean windspeeds and standard deviations of the windspeeds at each location over all the days \n",
    "\n",
    "#### A different set of numbers for each location."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.describe(percentiles=[])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create a DataFrame called day_stats and calculate the min, max and mean windspeed and standard deviations of the windspeeds across all the locations at each day.\n",
    "\n",
    "#### A different set of numbers for each day."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create the dataframe\n",
    "day_stats = pd.DataFrame()\n",
    "\n",
    "# this time we determine axis equals to one so it gets each row.\n",
    "day_stats['min'] = data.min(axis = 1) # min\n",
    "day_stats['max'] = data.max(axis = 1) # max \n",
    "day_stats['mean'] = data.mean(axis = 1) # mean\n",
    "day_stats['std'] = data.std(axis = 1) # standard deviations\n",
    "\n",
    "day_stats.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Find the average windspeed in January for each location.  \n",
    "#### Treat January 1961 and January 1962 both as January."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.loc[data.index.month == 1].mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Downsample the record to a yearly frequency for each location."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.groupby(data.index.to_period('A')).mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Downsample the record to a monthly frequency for each location."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.groupby(data.index.to_period('M')).mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Downsample the record to a weekly frequency for each location."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.groupby(data.index.to_period('W')).mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculate the min, max and mean windspeeds and standard deviations of the windspeeds across all locations for each week (assume that the first week starts on January 2 1961) for the first 52 weeks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# resample data to 'W' week and use the functions\n",
    "weekly = data.resample('W').agg(['min','max','mean','std'])\n",
    "\n",
    "# slice it for the first 52 weeks and locations\n",
    "weekly.loc[weekly.index[1:53], \"RPT\":\"MAL\"] .head(10)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
